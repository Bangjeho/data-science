{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "digits = datasets.load_digits()\n",
    "plt.imshow(digits.images[0],cmap='binary')\n",
    "plt.show()\n",
    "print(digits.target[0])\n",
    "# dir(digits)\n",
    "# digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15,5))\n",
    "for i in range(0,10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(digits.images[i], cmap = 'binary')\n",
    "    plt.title(digits.target[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = digits.images.reshape((digits.images.shape[0],\n",
    "                           digits.images.shape[1] * digits.images.shape[2]))\n",
    "y = digits.target\n",
    "\n",
    "x_train = x[:1000]\n",
    "y_train = y[:1000]\n",
    "\n",
    "x_test = x[1000:]\n",
    "y_test = y[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,40,20),\n",
    "                   activation='logistic',\n",
    "                   solver = 'sgd',\n",
    "                   tol = 1e-4,\n",
    "                   learning_rate_init=.1,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.34056279\n",
      "Iteration 2, loss = 2.30127970\n",
      "Iteration 3, loss = 2.31110943\n",
      "Iteration 4, loss = 2.30466661\n",
      "Iteration 5, loss = 2.30422721\n",
      "Iteration 6, loss = 2.30060950\n",
      "Iteration 7, loss = 2.29964484\n",
      "Iteration 8, loss = 2.29802906\n",
      "Iteration 9, loss = 2.29611083\n",
      "Iteration 10, loss = 2.29633447\n",
      "Iteration 11, loss = 2.29221714\n",
      "Iteration 12, loss = 2.29088830\n",
      "Iteration 13, loss = 2.28844653\n",
      "Iteration 14, loss = 2.28229666\n",
      "Iteration 15, loss = 2.27831367\n",
      "Iteration 16, loss = 2.27122644\n",
      "Iteration 17, loss = 2.26151863\n",
      "Iteration 18, loss = 2.24916777\n",
      "Iteration 19, loss = 2.23030948\n",
      "Iteration 20, loss = 2.20673986\n",
      "Iteration 21, loss = 2.17258709\n",
      "Iteration 22, loss = 2.12165486\n",
      "Iteration 23, loss = 2.05608658\n",
      "Iteration 24, loss = 1.97581181\n",
      "Iteration 25, loss = 1.89359441\n",
      "Iteration 26, loss = 1.81682664\n",
      "Iteration 27, loss = 1.74736549\n",
      "Iteration 28, loss = 1.69086673\n",
      "Iteration 29, loss = 1.64022676\n",
      "Iteration 30, loss = 1.59398115\n",
      "Iteration 31, loss = 1.54640030\n",
      "Iteration 32, loss = 1.49226910\n",
      "Iteration 33, loss = 1.43718104\n",
      "Iteration 34, loss = 1.37552403\n",
      "Iteration 35, loss = 1.31874490\n",
      "Iteration 36, loss = 1.24222961\n",
      "Iteration 37, loss = 1.17743790\n",
      "Iteration 38, loss = 1.12442525\n",
      "Iteration 39, loss = 1.06523446\n",
      "Iteration 40, loss = 1.02187642\n",
      "Iteration 41, loss = 0.96434025\n",
      "Iteration 42, loss = 0.91985070\n",
      "Iteration 43, loss = 0.86875348\n",
      "Iteration 44, loss = 0.82872058\n",
      "Iteration 45, loss = 0.79308668\n",
      "Iteration 46, loss = 0.74135217\n",
      "Iteration 47, loss = 0.69440240\n",
      "Iteration 48, loss = 0.66924295\n",
      "Iteration 49, loss = 0.62246287\n",
      "Iteration 50, loss = 0.59534496\n",
      "Iteration 51, loss = 0.54667776\n",
      "Iteration 52, loss = 0.51263115\n",
      "Iteration 53, loss = 0.51219851\n",
      "Iteration 54, loss = 0.44851938\n",
      "Iteration 55, loss = 0.41960169\n",
      "Iteration 56, loss = 0.38404736\n",
      "Iteration 57, loss = 0.35544103\n",
      "Iteration 58, loss = 0.33205211\n",
      "Iteration 59, loss = 0.30801460\n",
      "Iteration 60, loss = 0.29091325\n",
      "Iteration 61, loss = 0.26729665\n",
      "Iteration 62, loss = 0.24753113\n",
      "Iteration 63, loss = 0.22611983\n",
      "Iteration 64, loss = 0.20833450\n",
      "Iteration 65, loss = 0.19530940\n",
      "Iteration 66, loss = 0.18730820\n",
      "Iteration 67, loss = 0.16642073\n",
      "Iteration 68, loss = 0.15382986\n",
      "Iteration 69, loss = 0.14206000\n",
      "Iteration 70, loss = 0.13260235\n",
      "Iteration 71, loss = 0.12409351\n",
      "Iteration 72, loss = 0.11607202\n",
      "Iteration 73, loss = 0.10807668\n",
      "Iteration 74, loss = 0.10117556\n",
      "Iteration 75, loss = 0.09571621\n",
      "Iteration 76, loss = 0.09077925\n",
      "Iteration 77, loss = 0.08506459\n",
      "Iteration 78, loss = 0.08025570\n",
      "Iteration 79, loss = 0.07639825\n",
      "Iteration 80, loss = 0.07297601\n",
      "Iteration 81, loss = 0.06912698\n",
      "Iteration 82, loss = 0.06614387\n",
      "Iteration 83, loss = 0.06320311\n",
      "Iteration 84, loss = 0.06081441\n",
      "Iteration 85, loss = 0.05799307\n",
      "Iteration 86, loss = 0.05534416\n",
      "Iteration 87, loss = 0.05316149\n",
      "Iteration 88, loss = 0.05085487\n",
      "Iteration 89, loss = 0.04866753\n",
      "Iteration 90, loss = 0.04669521\n",
      "Iteration 91, loss = 0.04469080\n",
      "Iteration 92, loss = 0.04306326\n",
      "Iteration 93, loss = 0.04166325\n",
      "Iteration 94, loss = 0.04025323\n",
      "Iteration 95, loss = 0.03878934\n",
      "Iteration 96, loss = 0.03771196\n",
      "Iteration 97, loss = 0.03649553\n",
      "Iteration 98, loss = 0.03538401\n",
      "Iteration 99, loss = 0.03445812\n",
      "Iteration 100, loss = 0.03332210\n",
      "Iteration 101, loss = 0.03246057\n",
      "Iteration 102, loss = 0.03164974\n",
      "Iteration 103, loss = 0.03082643\n",
      "Iteration 104, loss = 0.03003201\n",
      "Iteration 105, loss = 0.02917313\n",
      "Iteration 106, loss = 0.02849806\n",
      "Iteration 107, loss = 0.02782109\n",
      "Iteration 108, loss = 0.02716389\n",
      "Iteration 109, loss = 0.02657195\n",
      "Iteration 110, loss = 0.02592554\n",
      "Iteration 111, loss = 0.02535913\n",
      "Iteration 112, loss = 0.02477227\n",
      "Iteration 113, loss = 0.02429723\n",
      "Iteration 114, loss = 0.02383136\n",
      "Iteration 115, loss = 0.02325492\n",
      "Iteration 116, loss = 0.02284763\n",
      "Iteration 117, loss = 0.02239805\n",
      "Iteration 118, loss = 0.02190335\n",
      "Iteration 119, loss = 0.02154383\n",
      "Iteration 120, loss = 0.02107333\n",
      "Iteration 121, loss = 0.02070453\n",
      "Iteration 122, loss = 0.02035424\n",
      "Iteration 123, loss = 0.01997521\n",
      "Iteration 124, loss = 0.01962608\n",
      "Iteration 125, loss = 0.01928151\n",
      "Iteration 126, loss = 0.01897495\n",
      "Iteration 127, loss = 0.01863557\n",
      "Iteration 128, loss = 0.01831746\n",
      "Iteration 129, loss = 0.01803487\n",
      "Iteration 130, loss = 0.01771697\n",
      "Iteration 131, loss = 0.01741226\n",
      "Iteration 132, loss = 0.01715956\n",
      "Iteration 133, loss = 0.01685378\n",
      "Iteration 134, loss = 0.01659841\n",
      "Iteration 135, loss = 0.01634394\n",
      "Iteration 136, loss = 0.01612202\n",
      "Iteration 137, loss = 0.01587480\n",
      "Iteration 138, loss = 0.01564484\n",
      "Iteration 139, loss = 0.01543333\n",
      "Iteration 140, loss = 0.01518704\n",
      "Iteration 141, loss = 0.01495447\n",
      "Iteration 142, loss = 0.01476463\n",
      "Iteration 143, loss = 0.01454337\n",
      "Iteration 144, loss = 0.01434445\n",
      "Iteration 145, loss = 0.01414747\n",
      "Iteration 146, loss = 0.01396680\n",
      "Iteration 147, loss = 0.01378403\n",
      "Iteration 148, loss = 0.01359434\n",
      "Iteration 149, loss = 0.01342442\n",
      "Iteration 150, loss = 0.01324934\n",
      "Iteration 151, loss = 0.01308689\n",
      "Iteration 152, loss = 0.01291957\n",
      "Iteration 153, loss = 0.01276164\n",
      "Iteration 154, loss = 0.01260518\n",
      "Iteration 155, loss = 0.01246395\n",
      "Iteration 156, loss = 0.01230102\n",
      "Iteration 157, loss = 0.01217367\n",
      "Iteration 158, loss = 0.01201651\n",
      "Iteration 159, loss = 0.01188822\n",
      "Iteration 160, loss = 0.01176918\n",
      "Iteration 161, loss = 0.01162819\n",
      "Iteration 162, loss = 0.01150467\n",
      "Iteration 163, loss = 0.01137662\n",
      "Iteration 164, loss = 0.01125382\n",
      "Iteration 165, loss = 0.01112887\n",
      "Iteration 166, loss = 0.01101728\n",
      "Iteration 167, loss = 0.01090088\n",
      "Iteration 168, loss = 0.01077971\n",
      "Iteration 169, loss = 0.01067122\n",
      "Iteration 170, loss = 0.01056617\n",
      "Iteration 171, loss = 0.01045994\n",
      "Iteration 172, loss = 0.01036455\n",
      "Iteration 173, loss = 0.01026359\n",
      "Iteration 174, loss = 0.01015318\n",
      "Iteration 175, loss = 0.01005508\n",
      "Iteration 176, loss = 0.00996693\n",
      "Iteration 177, loss = 0.00986671\n",
      "Iteration 178, loss = 0.00977441\n",
      "Iteration 179, loss = 0.00968720\n",
      "Iteration 180, loss = 0.00959324\n",
      "Iteration 181, loss = 0.00951550\n",
      "Iteration 182, loss = 0.00942253\n",
      "Iteration 183, loss = 0.00933906\n",
      "Iteration 184, loss = 0.00925347\n",
      "Iteration 185, loss = 0.00917885\n",
      "Iteration 186, loss = 0.00910041\n",
      "Iteration 187, loss = 0.00901356\n",
      "Iteration 188, loss = 0.00893631\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 40, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 2 0 0 9 7 6 3 2 9]\n",
      "[2 8 2 0 0 1 7 6 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(x_test)\n",
    "print(predictions[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77,  0,  0,  0,  0,  0,  2,  0,  0,  0],\n",
       "       [ 1, 69,  2,  0,  2,  0,  1,  0,  1,  4],\n",
       "       [ 0,  0, 67,  9,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  5, 70,  0,  3,  1,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0, 76,  0,  3,  0,  2,  1],\n",
       "       [ 3,  0,  0,  0,  0, 71,  1,  3,  4,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0, 79,  0,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  0,  0, 76,  0,  2],\n",
       "       [ 0,  3,  1,  2,  2,  5,  0,  1, 60,  2],\n",
       "       [ 0,  0,  0,  3,  0,  2,  0,  2,  1, 73]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pradicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>87</td>\n",
       "      <td>82</td>\n",
       "      <td>68</td>\n",
       "      <td>82</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pradicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          77   0   0   0   0   0   2   0   0   0   79\n",
       "1           1  69   2   0   2   0   1   0   1   4   80\n",
       "2           0   0  67   9   0   1   0   0   0   0   77\n",
       "3           0   0   5  70   0   3   1   0   0   0   79\n",
       "4           0   1   0   0  76   0   3   0   2   1   83\n",
       "5           3   0   0   0   0  71   1   3   4   0   82\n",
       "6           0   1   0   0   0   0  79   0   0   0   80\n",
       "7           0   2   0   0   0   0   0  76   0   2   80\n",
       "8           0   3   1   2   2   5   0   1  60   2   76\n",
       "9           0   0   0   3   0   2   0   2   1  73   81\n",
       "All        81  76  75  84  80  82  87  82  68  82  797"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test,predictions,rownames=[\"True\"],colnames=[\"pradicted\"],margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "for i in range(0,len(y_test)):\n",
    "    if predictions[i] == 9:\n",
    "        if y_test[i] == 1:\n",
    "            error.append(i+1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAABsCAYAAADpNT72AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABBFJREFUeJzt3TFOJEcUBuAq7wZ2BAdwwA0gcA5ETjkC5A64ASA5B06wnGAFNxhyB3ACIHEMoaWV2sE6sCxPFaaZ7f7H3ydN9ChNzRPzq6GfquswDAUg2XdTbwBgLEEGxBNkQDxBBsQTZEA8QQbEE2RAvPggq7X+Umv9rdb6R631aur9zJEe9elR35x79HHqDbyD30spv5ZSfi6l/DDxXuZKj/r0qG+2PYoPsmEYPpdSSq31p1LKjxNvZ5b0qE+P+ubco/g/LQEEGRBPkAHxBBkQL/6f/bXWj+Xr5/hQSvlQa/2+lPJlGIYv0+5sPvSoT4/6Zt2jYRiiX6WU01LK8I/X6dT7mtNLj/Ro3XtU/9ogQCz/IwPiCTIgniAD4gkyIJ4gA+Ktao5sZbdCn5+fl9YuLi6aa8/Ozpr1h4eHpbWtra3m2lJK7f3A30zSn9PT0+bay8vLZv38/Hxp7fj4uLm2/Lf+lLLCHrVcXV0160dHR836uvTo7u5uae0Vn6Op1eO3fs9ckQHxBBkQT5AB8QQZEE+QAfEEGRBPkAHxZnce2c3NTbN+cnKytHZ/fz/qvV8xwzK5xWLRrLdmfMb25+DgYNT699Sal7u9vW2u/fTp09Ja7/evp7WvOenNXLZmDl9eXka99yq+Z67IgHiCDIgnyIB4ggyIJ8iAeIIMiDfJ+EXrNn7v9vfGxsbS2u7ubnNt77b8XLRuffeOImr1Z3t7u7m2N54xp9GCw8PDpbUxIxRjezQnrVGd3pFOrf5eX1831z49PTXrrSOCdnZ2mmuXcUUGxBNkQDxBBsQTZEA8QQbEE2RAPEEGxJtkjqw1w9KbI2kdU9M7miRljqw1Z7e5udlc2+pPb3aoNyPVe+9vqfVZ9vb2mmtbM1KtGadSStnf32/W56R1XM6YmcDeHFnPW2fFWlyRAfEEGRBPkAHxBBkQT5AB8QQZEG+S8YvW7ddV3Jp9rVUcL/IWc+1PazzjWz+BalU9GvuEoDlJeCrYe3FFBsQTZEA8QQbEE2RAPEEGxBNkQDxBBsSbZI5srub0uLM5aj1qjq/mdNTRqvS+J71H6q2CKzIgniAD4gkyIJ4gA+IJMiCeIAPiCTIg3lrNkY2d4WmdR9Z7xNj/wWKxWFpbl/48PDyMWv/4+Pg+G5mx3pltvTmzVv2t32FXZEA8QQbEE2RAPEEGxBNkQDxBBsRbq/GL1vjEa6z7MT6t8YnXcERN37r0aMx3qdcD4xcA/0KQAfEEGRBPkAHxBBkQT5AB8QQZEK8OwzD1HgBGcUUGxBNkQDxBBsQTZEA8QQbEE2RAPEEGxBNkQDxBBsQTZEA8QQbEE2RAPEEGxBNkQDxBBsQTZEA8QQbEE2RAPEEGxBNkQDxBBsQTZEA8QQbE+xO8aFSiJOqoJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (5,5))\n",
    "for i in range(0,len(error)):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(digits.images[error[i]], cmap = 'binary')\n",
    "    plt.title(digits.target[error[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
